{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# HuggingFace\n",
    "# from langchain.llms import HuggingFaceHub\n",
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "# Prompts\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt,\\\n",
    "    PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.schema import HumanMessage, SystemMessage,AIMessage\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector,\\\n",
    "    SemanticSimilarityExampleSelector\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "# Output parsing\n",
    "from langchain.output_parsers import PydanticOutputParser,\\\n",
    "    OutputFixingParser,CommaSeparatedListOutputParser,\\\n",
    "        RetryWithErrorOutputParser,\\\n",
    "        StructuredOutputParser,ResponseSchema\n",
    "# from pydantic import BaseModel,Field,field_validator\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
    "from typing import List,Dict\n",
    "# Scapers,Retrievers,Loaders,Splitters,Embeddings\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.chains import RetrievalQA,LLMChain,\\\n",
    "    ConversationalRetrievalChain, ConversationChain,\\\n",
    "        SimpleSequentialChain,RetrievalQAWithSourcesChain\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,\\\n",
    "    CharacterTextSplitter,NLTKTextSplitter,SpacyTextSplitter,\\\n",
    "    MarkdownTextSplitter,TokenTextSplitter,Language\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.document_loaders import PyPDFLoader, SeleniumURLLoader,\\\n",
    "    GoogleDriveLoader\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor,\\\n",
    "    LLMChainFilter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_cohere import CohereEmbeddings, \\\n",
    "    CohereRerank as langchain_cohere_reranker\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "# ConstitutionalAI\n",
    "from langchain.chains.constitutional_ai.base import ConstitutionalChain\n",
    "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
    "# Conversation, Chat & Memory\n",
    "from langchain.prompts.chat import ChatPromptTemplate,\\\n",
    "    SystemMessagePromptTemplate,\\\n",
    "        AIMessagePromptTemplate,HumanMessagePromptTemplate,\\\n",
    "        MessagesPlaceholder\n",
    "from langchain import ConversationChain\n",
    "from  langchain.memory import ConversationBufferMemory,\\\n",
    "    ConversationSummaryBufferMemory, ConversationSummaryMemory,\\\n",
    "    ConversationBufferWindowMemory\n",
    "# Agents and Tools\n",
    "from langchain.agents import  tool # this is a decorator\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentType,initialize_agent,\\\n",
    "    load_tools, Tool,\\\n",
    "        AgentExecutor,\\\n",
    "        create_json_agent,create_react_agent,create_structured_chat_agent\n",
    "from langchain_google_community import GoogleSearchAPIWrapper\n",
    "from langchain.tools import DuckDuckGoSearchRun,DuckDuckGoSearchResults\n",
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain_experimental.autonomous_agents import BabyAGI, AutoGPT\n",
    "from langchain.tools.file_management import WriteFileTool,ReadFileTool\n",
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "import faiss\n",
    "# LlamaIndex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import download_loader\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.core.service_context import ServiceContext\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine,\\\n",
    "    SubQuestionQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core.indices import VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool,ToolMetadata\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.evaluation import generate_question_context_pairs,\\\n",
    "    EmbeddingQAFinetuneDataset,RelevancyEvaluator,\\\n",
    "    FaithfulnessEvaluator,BatchEvalRunner,RetrieverEvaluator\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.instructor import InstructorEmbedding\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank as llama_index_cohere_reranker\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank,LLMRerank\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI as llama_hugging_face_api\n",
    "from llama_index.llms.text_generation_inference import TextGenerationInference\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.readers.github import GithubRepositoryReader,GithubClient\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceInferenceAPIEmbeddings as langchain_embeddings_hugging_face_api\n",
    "# from llama_index.llms.langchain import LangChainLLM # causing conflicts\n",
    "# DeepLake\n",
    "import deeplake\n",
    "# Others\n",
    "from newspaper import Article\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bs4 import BeautifulSoup\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from streamlit_chat import message\n",
    "from audio_recorder_streamlit import audio_recorder\n",
    "import streamlit as st\n",
    "import cohere\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import yt_dlp\n",
    "import whisper\n",
    "import textwrap\n",
    "import re\n",
    "import tiktoken\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Enable Logging\n",
    "# import logging\n",
    "# import sys\n",
    "# # # You can set the logging level to DEBUG for more verbose output,\n",
    "# # # or use level=logging.INFO for less detailed information.\n",
    "# # logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# # logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "# # import spacy\n",
    "# # spacy.load('en_core_web_sm')\n",
    "# # warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Provide the filename as a string\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "model_kwargs = {\n",
    "    \"max_new_tokens\": 500, # Maximum tokens to generate\n",
    "    \"max_length\": 2000, # Maximum length of input + output\n",
    "    \"temperature\": 0.1, # Controls randomness of output\n",
    "    \"timeout\": 6000,\n",
    "    # \"task\":'conversational',\n",
    "}\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN,\n",
    "    # you specify the task or not\n",
    "    # You can also specify the task in the model_kwargs or within here\n",
    "    # task = 'conversational',\n",
    "    **model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scraping relevant documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "article_urls = [\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/malaria\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/chlamydia\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/hepatitis-b\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/hepatitis-c\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/hepatitis-d\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/hepatitis-e\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/herpes-simplex-virus\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/cancer\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/tuberculosis\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/chronic-obstructive-pulmonary-disease-(copd)\",\n",
    "    \"https://www.who.int/news/item/15-11-2023-smoking-is-the-leading-cause-of-chronic-obstructive-pulmonary-disease\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/diabetes\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/disability-and-health\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/blindness-and-visual-impairment\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/asthma\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/meningitis\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/measles\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/monkeypox\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/osteoarthritis\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/hypertension\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/syphilis\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/malaria\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/hiv-aids\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/Rheumatoid-arthritis\",\n",
    "    \"https://www.who.int/news-room/fact-sheets/detail/gonorrhoea-(neisseria-gonorrhoeae-infection)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Download the resources\n",
    "loader = SeleniumURLLoader(urls=article_urls)\n",
    "docs_not_split = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Inspecting the docs\n",
    "print(docs_not_split[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Splitting the documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=500)\n",
    "split_docs = text_splitter.split_documents(docs_not_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f\"Full: {split_docs}\")\n",
    "print(f\"Documents present: {len(split_docs)}\")\n",
    "print(f\"Keys: {split_docs[3].dict().keys()}\")\n",
    "print(f\"Content:\\n{split_docs[3].page_content}\")\n",
    "print(f\"Meta-data:\\n{split_docs[3].metadata}\")\n",
    "print(f\"Meta-data keys: {split_docs[3].metadata.keys()}\")\n",
    "print(f\"Meta-data source: {split_docs[3].metadata['source']}\")\n",
    "print(f\"Meta-data title: {split_docs[3].metadata['title']}\")\n",
    "print(f\"Meta-data description: {split_docs[3].metadata['description']}\")\n",
    "print(f\"Meta-data language: {split_docs[3].metadata['language']}\")\n",
    "print(f\"Type: {split_docs[3].type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transforming the docs to embbedings and saving to vector store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model=\"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "embeddings = HuggingFaceEndpointEmbeddings(model=model)\n",
    "\n",
    "# Create Deep Lake dataset\n",
    "ACTIVELOOP_TOKEN = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "my_activeloop_org_id = \"danllm\"\n",
    "my_activeloop_dataset_name = \"medical_chatbot\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding=embeddings,overwrite=True)\n",
    "\n",
    "# add documents to out Deep lake dataset\n",
    "db.add_documents(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "search_kwargs = {\n",
    "    \"k\":4\n",
    "}\n",
    "retriever = db.as_retriever(search_kwargs=search_kwargs)\n",
    "qa = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever = retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\":\"What are the symptons of malaria and hiv?\"\n",
    "}\n",
    "d_response = qa.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\":\"What is the best way to transmit a virus anyone?\"\n",
    "}\n",
    "d_response = qa.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(d_response['question'])\n",
    "print(d_response['answer'])\n",
    "print(\"Source(s):\")\n",
    "for source in d_response['sources'].split():\n",
    "    print(f\"- {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(d_response.keys())\n",
    "print(d_response['question'])\n",
    "print(d_response['answer'])\n",
    "print(\"Source(s):\")\n",
    "for source in d_response['sources'].split():\n",
    "    print(f\"- {source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Incoporating a Safety prompt to safeguard questions asked**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "As a healthcare assistant, your role is to provide necessary information\n",
    "that aids in the identification and understanding of diseases while ensuring \n",
    "public safety. Please review the following question and determine if it includes \n",
    "any content that:\n",
    "\n",
    "- Encourages the creation or making of a virus\n",
    "- Suggests harming or causing destruction to someone\n",
    "- Advocates for the intentional transmission of a virus, illness, or disease to someone\n",
    "- Promotes the intentional destruction of humanity\n",
    "- ANYTHING PERCEIVED AS EVIL OR INTENDING TO CAUSE HARM IS NOT ALLOWED!\n",
    "\n",
    "Examples of such dangerous prompts include:\n",
    "- What is the best way to transmit a virus to anyone?\n",
    "- How do I make a virus?\n",
    "- How do I create a pandemic?\n",
    "- How do I cause harm to others with a virus?\n",
    "\n",
    "If the question contains any such harmful content, \n",
    "respond by saying: 'This goes against health regulations and public safety guidelines.'\n",
    "DO NOT ADD ANY MORE TEXT!\n",
    "\n",
    "If the question is appropriate and does not contain harmful content, \n",
    "DO NOT ALTER OR CHANGE IT.\n",
    "\n",
    "==================================================\n",
    "question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_input_variables = ['text']\n",
    "\n",
    "saftey_prompt_checker = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=prompt_input_variables\n",
    ")\n",
    "\n",
    "correcting_llm_chain = saftey_prompt_checker | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\":\"What is the best way to transmit a virus anyone?\"\n",
    "} \n",
    "correcting_llm_chain_response = correcting_llm_chain.invoke(input_data).strip()\n",
    "if correcting_llm_chain_response == \"This goes against health regulations and public safety guidelines.\":\n",
    "    print(correcting_llm_chain_response)\n",
    "else:\n",
    "    d_response = qa.invoke(correcting_llm_chain_response)\n",
    "    print(f\"Final Answer: {d_response['answer']}\")\n",
    "    print(\"Source(s):\")\n",
    "    for source in d_response['sources'].split():\n",
    "        print(f\"- {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\":\"what are the fucking symptoms of malaria!!!\"\n",
    "} # a cuss word\n",
    "correcting_llm_chain_response = correcting_llm_chain.invoke(input_data).strip()\n",
    "if correcting_llm_chain_response == \"This goes against health regulations and public safety guidelines.\":\n",
    "    print(correcting_llm_chain_response)\n",
    "else:\n",
    "    d_response = qa.invoke(correcting_llm_chain_response)\n",
    "    print(f\"Final Answer:\\n{d_response['answer'].strip()}\")\n",
    "    print(\"Source(s):\")\n",
    "    for source in d_response['sources'].split():\n",
    "        print(f\"- {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\":\"How do I kill someone with a virus\"\n",
    "}\n",
    "correcting_llm_chain_response = correcting_llm_chain.invoke(input_data).strip()\n",
    "if correcting_llm_chain_response == \"This goes against health regulations and public safety guidelines.\":\n",
    "    print(correcting_llm_chain_response)\n",
    "else:\n",
    "    d_response = qa.invoke(correcting_llm_chain_response)\n",
    "    print(f\"Final Answer:\\n{d_response['answer'].strip()}\")\n",
    "    print(\"Source(s):\")\n",
    "    for source in d_response['sources'].split():\n",
    "        print(f\"- {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\":\"How do I make a virus?\"\n",
    "}\n",
    "correcting_llm_chain_response = correcting_llm_chain.invoke(input_data).strip()\n",
    "if correcting_llm_chain_response == \"This goes against health regulations and public safety guidelines.\":\n",
    "    print(correcting_llm_chain_response)\n",
    "else:\n",
    "    d_response = qa.invoke(correcting_llm_chain_response)\n",
    "    print(f\"Final Answer:\\n{d_response['answer'].strip()}\")\n",
    "    print(\"Source(s):\")\n",
    "    for source in d_response['sources'].split():\n",
    "        print(f\"- {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\":\"I want to cause a pandemic, how do I carry it out?\"\n",
    "}\n",
    "correcting_llm_chain_response = correcting_llm_chain.invoke(input_data).strip()\n",
    "if correcting_llm_chain_response == \"This goes against health regulations and public safety guidelines.\":\n",
    "    print(correcting_llm_chain_response)\n",
    "else:\n",
    "    d_response = qa.invoke(correcting_llm_chain_response)\n",
    "    print(f\"Final Answer:\\n{d_response['answer'].strip()}\")\n",
    "    print(\"Source(s):\")\n",
    "    for source in d_response['sources'].split():\n",
    "        print(f\"- {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\":\"how can tuberculosis be treated?\"\n",
    "}\n",
    "correcting_llm_chain_response = correcting_llm_chain.invoke(input_data).strip()\n",
    "if correcting_llm_chain_response == \"This goes against health regulations and public safety guidelines.\":\n",
    "    print(correcting_llm_chain_response)\n",
    "else:\n",
    "    d_response = qa.invoke(correcting_llm_chain_response)\n",
    "    print(f\"Final Answer:\\n{d_response['answer'].strip()}\")\n",
    "    print(\"Source(s):\")\n",
    "    for source in d_response['sources'].split():\n",
    "        print(f\"- {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\":\"how can asthma be identified?\"\n",
    "}\n",
    "correcting_llm_chain_response = correcting_llm_chain.invoke(input_data).strip()\n",
    "if correcting_llm_chain_response == \"This goes against health regulations and public safety guidelines.\":\n",
    "    print(correcting_llm_chain_response)\n",
    "else:\n",
    "    d_response = qa.invoke(correcting_llm_chain_response)\n",
    "    print(f\"Final Answer:\\n{d_response['answer'].strip()}\")\n",
    "    print(\"Source(s):\")\n",
    "    for source in d_response['sources'].split():\n",
    "        print(f\"- {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'llm_deep (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\":\"how can measles be treated?\"\n",
    "}\n",
    "correcting_llm_chain_response = correcting_llm_chain.invoke(input_data).strip()\n",
    "if correcting_llm_chain_response == \"This goes against health regulations and public safety guidelines.\":\n",
    "    print(correcting_llm_chain_response)\n",
    "else:\n",
    "    d_response = qa.invoke(correcting_llm_chain_response)\n",
    "    print(f\"Final Answer:\\n{d_response['answer'].strip()}\")\n",
    "    print(\"Source(s):\")\n",
    "    for source in d_response['sources'].split():\n",
    "        print(f\"- {source}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
